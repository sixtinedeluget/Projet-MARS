{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x4Ei1zyd-7L",
        "outputId": "2340fcf4-0596-44af-b82c-3e322652609f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.8.11)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [15 lines of output]\n",
            "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
            "      rather than 'sklearn' for pip commands.\n",
            "      \n",
            "      Here is how to fix this error in the main use cases:\n",
            "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
            "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
            "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
            "      - if the 'sklearn' package is used by one of your dependencies,\n",
            "        it would be great if you take some time to track which package uses\n",
            "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
            "      - as a last resort, set the environment variable\n",
            "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
            "      \n",
            "      More information is available at\n",
            "      https://github.com/scikit-learn/sklearn-pypi-package\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy sklearn PyPDF2 nltk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzuAITqYeJIT",
        "outputId": "6837ae83-ca76-4530-c438-535e18e48415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.8.11)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [15 lines of output]\n",
            "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
            "      rather than 'sklearn' for pip commands.\n",
            "      \n",
            "      Here is how to fix this error in the main use cases:\n",
            "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
            "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
            "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
            "      - if the 'sklearn' package is used by one of your dependencies,\n",
            "        it would be great if you take some time to track which package uses\n",
            "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
            "      - as a last resort, set the environment variable\n",
            "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
            "      \n",
            "      More information is available at\n",
            "      https://github.com/scikit-learn/sklearn-pypi-package\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy sklearn PyPDF2 nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYLPcpj8eUkl",
        "outputId": "6af79a50-f6eb-46ce-df85-afb8f1015d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by482X8peXHw",
        "outputId": "f839c45f-9023-4faa-f953-5dcdf2253f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.7.2\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "ZbIbqodLeaTW",
        "outputId": "244b27b0-65d5-4b18-d806-027e9afaae91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compétences\n",
            "Visualisation & Reporting\n",
            "Tableaux de bor d, dataviz,\n",
            "reporting\n",
            "Outils & Langages\n",
            "Python, R, Git, Jup yter, Po wer\n",
            "BI, Shiny\n",
            "Analyse de données\n",
            "Régr ession, classiﬁcation,\n",
            "analyses multivariées\n",
            "(ACP/MF A), modélisation\n",
            "prédictive pour appui\n",
            "décisionnel\n",
            "Gestion de données\n",
            "Netto yage, structur ation,\n",
            "intégr ation multi-sour ces,\n",
            "contr ôle qualité, cr éation\n",
            "d’indicateurs\n",
            "Soft Skills\n",
            "Analyse et esprit critique\n",
            "Rigueur et or ganisation\n",
            "Résolution de pr oblèmes\n",
            "Communication\n",
            "Travail en équipe\n",
            "Langues\n",
            "Français : Cour ant\n",
            "Anglais : Professionnel\n",
            "Arabe : Cour ant\n",
            "Réseaux sociauxNassima EL HILALI\n",
            "Data Analyst / Data Scientist\n",
            "Je suis Data Scientist en M2 Data Science et ingénieur e spécialisée en agr oéconomie,\n",
            "avec un pr oﬁl pluridisciplinair e orienté vers l’ analyse quantitative, la modélisation\n",
            "statistique et l’ aide à la décision. J’ ai de l’ expérience en manipulation et valorisation\n",
            "de données hétér ogènes, en modélisation pr édictive et en cr éation de tableaux de\n",
            "bord pour appuyer le pilotage d’ activité. Je suis disponible pour un stage de 6 mois à\n",
            "partir de fé vrier 2026.\n",
            "Diplômes et Formations\n",
            "Expériences professionnelles\n",
            "Projets académiquesnassima.elhilali.pr o@gmail.\n",
            "com\n",
            "Permis de conduir e B \n",
            "Disponible dès\n",
            "Février/Mars 2026\n",
            "Ile de Fr ance\n",
            "+33 6 03 54 78 77 \n",
            "@nassimaelhilali-hub\n",
            "@Nassima EL HILALIMaster M2 – Data Science pour la Biologie\n",
            "Depuis 2024 Institut Agr o Rennes-Angers  Rennes, FRANCE\n",
            " Machine Learning, Modèles pr édictifs, Statistiques avancées\n",
            "Diplôme d’Ingénieur d’État – Spécialisation Agr oéconomie\n",
            "De 2019  à 2024 École Nationale d’ Agricultur e (ENA)  Meknès, MAROC\n",
            "Data Scientist (Stage)\n",
            "De février 2024  à juillet 2024\n",
            "Conseil, Ingénierie, Dé veloppement (CID)  Rabat, MAROC\n",
            "Objectif : amélior er la performance économique et opér ationnelle\n",
            "d’exploitations agricoles.\n",
            "Développement d’ un modèle d’ optimisation économique (données IoT +\n",
            "terrain).\n",
            "Conception d’ outils d’ aide à la décision : pr ototype mobile (Figma) et chatbot\n",
            "IA.\n",
            "Analyse et visualisation des données pour appuyer l’ amélior ation de\n",
            "processus métier.\n",
            "Data Analyst (Stage)\n",
            "De mai 2023  à juillet 2023\n",
            "Conseil, Ingénierie, Dé veloppement (CID)  Rabat, MAROC\n",
            "Objectif : pr oduir e des insights pour la prise de décision str atégique.\n",
            "Collecte et consolidation de données climatiques & économiques multi-\n",
            "sour ces.\n",
            "Développement de dashboar ds automatisés et analyses de tendances.\n",
            "Traitement statistique (Stage)\n",
            "De janvier 2023  à février 2023\n",
            "Oﬃce National du Conseil Agricole (ONCA)  Région du Saiss, MAROC\n",
            "Analyses statistiques pour orienter les r ecommandations agricoles.\n",
            "Création de gr aphiques et tableaux de bor d automatisés.\n",
            "Char gée Qualité - Analyse des Données (Stage)\n",
            "D'août 2022  à septembr e 2022\n",
            "Azur a (Gr and gr oupe agr oalimentair e) Agadir, MAROC\n",
            "Analyse de données de pr oduction et suivi d’indicateurs qualité.\n",
            "Classiﬁcation d’images d’ espèces animales — CNN (2025)\n",
            "2025 Institut Agr o-Rennes  Rennes\n",
            "Modèle CNN pour classiﬁer 10 espèces animales à partir d’images.\n",
            "Pipeline complet + data augmentation pour amélior er la r obustesse.\n",
            "Analyse des performances et interpr étation des err eurs (Python, PyT orch).\n",
            "Dashboar ds décisionnels — Shiny (2025)\n",
            "2025 Institut Agr o-Rennes  Rennes\n",
            "Tableaux de bor d inter actifs pour suivr e des indicateurs.\n",
            "Structur ation des données et visualisations sous R/Shiny .\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_resume_text(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in range(len(reader.pages)):\n",
        "            text += reader.pages[page].extract_text()\n",
        "    return text\n",
        "\n",
        "# Example usage:\n",
        "resume_text = extract_resume_text('CV__Nassima_EL_HILALI.pdf')\n",
        "print(resume_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFgl4YoVfJGB",
        "outputId": "17c1e14a-4415-4050-bf03-68a0789f8faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.0.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h5M4uZyqfMeV"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H79-wM4ifO0s",
        "outputId": "7afd9a4e-1435-4303-d053-292ad0ea1ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compétences\n",
            "Visualisation & Reporting\n",
            "Tableaux de bor d, dataviz,\n",
            "reporting\n",
            "Outils & Langages\n",
            "Python, R, Git, Jup yter, Po wer\n",
            "BI, Shiny\n",
            "Analyse de données\n",
            "Régr ession, classiﬁcation,\n",
            "analyses multivariées\n",
            "(ACP/MF A), modélisation\n",
            "prédictive pour appui\n",
            "décisionnel\n",
            "Gestion de données\n",
            "Netto yage, structur ation,\n",
            "intégr ation multi-sour ces,\n",
            "contr ôle qualité, cr éation\n",
            "d’indicateurs\n",
            "Soft Skills\n",
            "Analyse et esprit critique\n",
            "Rigueur et or ganisation\n",
            "Résolution de pr oblèmes\n",
            "Communication\n",
            "Travail en équipe\n",
            "Langues\n",
            "Français : Cour ant\n",
            "Anglais : Professionnel\n",
            "Arabe : Cour ant\n",
            "Réseaux sociauxNassima EL HILALI\n",
            "Data Analyst / Data Scientist\n",
            "Je suis Data Scientist en M2 Data Science et ingénieur e spécialisée en agr oéconomie,\n",
            "avec un pr oﬁl pluridisciplinair e orienté vers l’ analyse quantitative, la modélisation\n",
            "statistique et l’ aide à la décision. J’ ai de l’ expérience en manipulation et valorisation\n",
            "de données hétér ogènes, en modélisation pr édictive et en cr éation de tableaux de\n",
            "bord pour appuyer le pilotage d’ activité. Je suis disponible pour un stage de 6 mois à\n",
            "partir de fé vrier 2026.\n",
            "Diplômes et Formations\n",
            "Expériences professionnelles\n",
            "Projets académiquesnassima.elhilali.pr o@gmail.\n",
            "com\n",
            "Permis de conduir e B \n",
            "Disponible dès\n",
            "Février/Mars 2026\n",
            "Ile de Fr ance\n",
            "+33 6 03 54 78 77 \n",
            "@nassimaelhilali-hub\n",
            "@Nassima EL HILALIMaster M2 – Data Science pour la Biologie\n",
            "Depuis 2024 Institut Agr o Rennes-Angers  Rennes, FRANCE\n",
            " Machine Learning, Modèles pr édictifs, Statistiques avancées\n",
            "Diplôme d’Ingénieur d’État – Spécialisation Agr oéconomie\n",
            "De 2019  à 2024 École Nationale d’ Agricultur e (ENA)  Meknès, MAROC\n",
            "Data Scientist (Stage)\n",
            "De février 2024  à juillet 2024\n",
            "Conseil, Ingénierie, Dé veloppement (CID)  Rabat, MAROC\n",
            "Objectif : amélior er la performance économique et opér ationnelle\n",
            "d’exploitations agricoles.\n",
            "Développement d’ un modèle d’ optimisation économique (données IoT +\n",
            "terrain).\n",
            "Conception d’ outils d’ aide à la décision : pr ototype mobile (Figma) et chatbot\n",
            "IA.\n",
            "Analyse et visualisation des données pour appuyer l’ amélior ation de\n",
            "processus métier.\n",
            "Data Analyst (Stage)\n",
            "De mai 2023  à juillet 2023\n",
            "Conseil, Ingénierie, Dé veloppement (CID)  Rabat, MAROC\n",
            "Objectif : pr oduir e des insights pour la prise de décision str atégique.\n",
            "Collecte et consolidation de données climatiques & économiques multi-\n",
            "sour ces.\n",
            "Développement de dashboar ds automatisés et analyses de tendances.\n",
            "Traitement statistique (Stage)\n",
            "De janvier 2023  à février 2023\n",
            "Oﬃce National du Conseil Agricole (ONCA)  Région du Saiss, MAROC\n",
            "Analyses statistiques pour orienter les r ecommandations agricoles.\n",
            "Création de gr aphiques et tableaux de bor d automatisés.\n",
            "Char gée Qualité - Analyse des Données (Stage)\n",
            "D'août 2022  à septembr e 2022\n",
            "Azur a (Gr and gr oupe agr oalimentair e) Agadir, MAROC\n",
            "Analyse de données de pr oduction et suivi d’indicateurs qualité.\n",
            "Classiﬁcation d’images d’ espèces animales — CNN (2025)\n",
            "2025 Institut Agr o-Rennes  Rennes\n",
            "Modèle CNN pour classiﬁer 10 espèces animales à partir d’images.\n",
            "Pipeline complet + data augmentation pour amélior er la r obustesse.\n",
            "Analyse des performances et interpr étation des err eurs (Python, PyT orch).\n",
            "Dashboar ds décisionnels — Shiny (2025)\n",
            "2025 Institut Agr o-Rennes  Rennes\n",
            "Tableaux de bor d inter actifs pour suivr e des indicateurs.\n",
            "Structur ation des données et visualisations sous R/Shiny .\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_resume_text(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in range(len(reader.pages)):\n",
        "            text += reader.pages[page].extract_text()\n",
        "    return text\n",
        "\n",
        "# Example usage:\n",
        "resume_text = extract_resume_text('CV__Nassima_EL_HILALI.pdf')\n",
        "print(resume_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdyuiluBfeW3",
        "outputId": "fe41b75f-2e68-42a5-bcbe-b43e6fcf4abe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "compétences \n",
            " visualisation reporting \n",
            " tableaux de bor dataviz \n",
            " reporting \n",
            " outils langages \n",
            " python r git jup yter po wer \n",
            " bi shiny \n",
            " analyse de données \n",
            " régr ession classiﬁcation \n",
            " analyses multivariées \n",
            " acp mf modélisation \n",
            " prédictive pour appui \n",
            " décisionnel \n",
            " gestion de données \n",
            " netto yage structur ation \n",
            " intégr ation multi sour ces \n",
            " contr ôle qualité cr éation \n",
            " d’indicateurs \n",
            " soft skills \n",
            " analyse et esprit critique \n",
            " rigueur et ganisation \n",
            " résolution de pr oblèmes \n",
            " communication \n",
            " travail en équipe \n",
            " langues \n",
            " français cour ant \n",
            " anglais professionnel \n",
            " arabe cour ant \n",
            " réseaux sociauxnassima el hilali \n",
            " data analyst data scientist \n",
            " je suis data scientist en m2 data science et ingénieur e spécialisée en agr oéconomie \n",
            " avec un pr oﬁl pluridisciplinair e orienté vers l ’ analyse quantitative la modélisation \n",
            " statistique et l ’ aide à la décision j ’ ai de l ’ expérience en manipulation et valorisation \n",
            " de données hétér ogènes en modélisation pr édictive et en cr éation de tableaux de \n",
            " bord pour appuyer le pilotage ’ activité je suis disponible pour un stage de 6 mois à \n",
            " partir de fé vrier 2026 \n",
            " diplômes et formations \n",
            " expériences professionnelles \n",
            " projets académiquesnassima.elhilali.pr o@gmail \n",
            " com \n",
            " permis de conduir e b  \n",
            " disponible dès \n",
            " février mars 2026 \n",
            " ile de fr ance \n",
            " +33 6 03 54 78 77  \n",
            " @nassimaelhilali hub \n",
            " @nassima el hilalimaster m2 – data science pour la biologie \n",
            " depuis 2024 institut agr rennes angers   rennes france \n",
            "  machine learning modèles pr édictifs statistiques avancées \n",
            " diplôme d’ingénieur d’état – spécialisation agr oéconomie \n",
            " de 2019   à 2024 école nationale ’ agricultur e ena   meknès maroc \n",
            " data scientist stage \n",
            " de février 2024   à juillet 2024 \n",
            " conseil ingénierie dé veloppement cid   rabat maroc \n",
            " objectif amélior er la performance économique et opér ationnelle \n",
            " d’exploitations agricoles \n",
            " développement ’ un modèle ’ optimisation économique données iot \n",
            " terrain \n",
            " conception ’ outils ’ aide à la décision pr ototype mobile figma et chatbot \n",
            " ia \n",
            " analyse et visualisation des données pour appuyer l ’ amélior ation de \n",
            " processus métier \n",
            " data analyst stage \n",
            " de mai 2023   à juillet 2023 \n",
            " conseil ingénierie dé veloppement cid   rabat maroc \n",
            " objectif pr oduir e des insights pour la prise de décision str atégique \n",
            " collecte et consolidation de données climatiques économiques multi- \n",
            " sour ces \n",
            " développement de dashboar ds automatisés et analyses de tendances \n",
            " traitement statistique stage \n",
            " de janvier 2023   à février 2023 \n",
            " oﬃce national du conseil agricole onca   région du saiss maroc \n",
            " analyses statistiques pour orienter les r ecommandations agricoles \n",
            " création de gr aphiques et tableaux de bor automatisés \n",
            " char gée qualité analyse des données stage \n",
            " d'août 2022   à septembr e 2022 \n",
            " azur gr gr oupe agr oalimentair e agadir maroc \n",
            " analyse de données de pr oduction et suivi d’indicateurs qualité \n",
            " classiﬁcation d’images ’ espèces animales — cnn 2025 \n",
            " 2025 institut agr rennes   rennes \n",
            " modèle cnn pour classiﬁer 10 espèces animales à partir d’images \n",
            " pipeline complet data augmentation pour amélior er la r obustesse \n",
            " analyse des performances et interpr étation des err eurs python pyt orch \n",
            " dashboar ds décisionnels — shiny 2025 \n",
            " 2025 institut agr rennes   rennes \n",
            " tableaux de bor inter actifs pour suivr e des indicateurs \n",
            " structur ation des données et visualisations sous r shiny\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenize and remove stopwords/punctuation\n",
        "    doc = nlp(text)\n",
        "    clean_tokens = [token.text for token in doc if token.text not in stop_words and token.text not in string.punctuation]\n",
        "\n",
        "    return \" \".join(clean_tokens)\n",
        "\n",
        "# Example usage\n",
        "cleaned_resume = preprocess_text(resume_text)\n",
        "print(cleaned_resume)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-zLkdu9fs3J",
        "outputId": "23650e68-fad8-46e4-e406-1292a3e4e140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "looking data scientist 3 years experience python machine learning data analysis ...\n"
          ]
        }
      ],
      "source": [
        "job_description = \"\"\"We are looking for a Data Scientist with 3+ years of experience in Python, Machine Learning, and Data Analysis...\"\"\"\n",
        "cleaned_job_description = preprocess_text(job_description)\n",
        "print(cleaned_job_description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4gVY_9rCfwrP"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def vectorize_texts(resume, job_desc):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([resume, job_desc])\n",
        "    return vectors\n",
        "\n",
        "resume_vector, job_desc_vector = vectorize_texts(cleaned_resume, cleaned_job_description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kWH3TjSgDZ3",
        "outputId": "c85fc584-1edf-471c-c96d-3ac63a6cf29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resume-Job Description Similarity Score: 0.08985341931511699\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "similarity_score = cosine_similarity(resume_vector, job_desc_vector)\n",
        "print(f\"Resume-Job Description Similarity Score: {similarity_score[0][0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp4DdSwpf1Cs",
        "outputId": "e1597dfc-a690-40aa-fd2a-ce3968babeba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.1)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, tenacity, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.38.0 tenacity-8.5.0 watchdog-4.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqeYn9lXgZKO",
        "outputId": "43eac245-c398-4241-b12c-57163673bc21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "2024-09-24 00:50:04.375 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-24 00:50:04.606 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-09-24 00:50:04.618 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-24 00:50:04.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-24 00:50:04.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-24 00:50:04.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-24 00:50:04.638 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-24 00:50:04.643 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-24 00:50:04.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-24 00:50:04.647 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-24 00:50:04.649 Session state does not function when running a script without `streamlit run`\n",
            "2024-09-24 00:50:04.652 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-24 00:50:04.655 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import PyPDF2\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract resume text from a PDF\n",
        "def extract_resume_text(file):\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in range(len(reader.pages)):\n",
        "        text += reader.pages[page].extract_text()\n",
        "    return text\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    doc = nlp(text)\n",
        "    clean_tokens = [token.text for token in doc if token.text not in stop_words and token.text not in string.punctuation]\n",
        "    return \" \".join(clean_tokens)\n",
        "\n",
        "# Vectorize text and calculate cosine similarity\n",
        "def calculate_similarity(resume, job_desc):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([resume, job_desc])\n",
        "    similarity_score = cosine_similarity(vectors)[0][1]\n",
        "    return similarity_score\n",
        "\n",
        "# Streamlit App\n",
        "st.title(\"Resume Classifier and Job Matching System\")\n",
        "\n",
        "# Upload resume\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (PDF)\", type=\"pdf\")\n",
        "\n",
        "# Job description input\n",
        "job_desc = st.text_area(\"Paste Job Description\", height=150)\n",
        "\n",
        "# If both resume and job description are provided\n",
        "if uploaded_file and job_desc:\n",
        "    resume_text = extract_resume_text(uploaded_file)\n",
        "    cleaned_resume = preprocess_text(resume_text)\n",
        "    cleaned_job_description = preprocess_text(job_desc)\n",
        "\n",
        "    similarity_score = calculate_similarity(cleaned_resume, cleaned_job_description)\n",
        "\n",
        "    # Display similarity score\n",
        "    st.write(f\"Resume-Job Description Similarity Score: {similarity_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZBrFu1SggYx",
        "outputId": "53b6f7c0-e8cc-4511-cf19-cf8b251237b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igpP9NnvkXZu",
        "outputId": "34c31464-6f22-44b4-aeb0-8567b92f98c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken cr_2mUlcTcyRemtKUFd8XUTMFyjUHN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF9NrzIekeWC",
        "outputId": "a666e03d-7cdf-4d23-8435-630c17a5f24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2mUoiWYULIxq7xds0QdQl3Xd0wa_7SaaUsUxNKBchM5K2Uqwf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGK3HMPQm3VR",
        "outputId": "b8fdb69e-57e8-4c5a-b3a0-ea6d9c52ff8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://2c00-34-150-179-246.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Start Streamlit app\n",
        "!streamlit run app.py &>/dev/null&\n",
        "\n",
        "# Expose the port explicitly using http\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(f\"Streamlit app is live at: {public_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dI-HKW5oMmb",
        "outputId": "4a75c180-f73f-46fd-b7bd-040ac150e079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root       11117  0.0  0.0   6484  2308 ?        S    01:23   0:00 grep streamlit\n"
          ]
        }
      ],
      "source": [
        "!ps aux | grep streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XwRvEqRUoSTC"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py --server.port 8501 &>/dev/null&\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVBE6LHbnEm0",
        "outputId": "d3b4041d-d388-4e9b-d87d-6ec8d2c78f65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root       11254  0.0  0.0   6484  2256 ?        S    01:24   0:00 grep streamlit\n"
          ]
        }
      ],
      "source": [
        "!ps aux | grep streamlit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparer plusieurs CVs a une offre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
