{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x4Ei1zyd-7L",
        "outputId": "2340fcf4-0596-44af-b82c-3e322652609f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.8.11)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [15 lines of output]\n",
            "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
            "      rather than 'sklearn' for pip commands.\n",
            "      \n",
            "      Here is how to fix this error in the main use cases:\n",
            "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
            "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
            "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
            "      - if the 'sklearn' package is used by one of your dependencies,\n",
            "        it would be great if you take some time to track which package uses\n",
            "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
            "      - as a last resort, set the environment variable\n",
            "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
            "      \n",
            "      More information is available at\n",
            "      https://github.com/scikit-learn/sklearn-pypi-package\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy sklearn PyPDF2 nltk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzuAITqYeJIT",
        "outputId": "6837ae83-ca76-4530-c438-535e18e48415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.8.11)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [15 lines of output]\n",
            "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
            "      rather than 'sklearn' for pip commands.\n",
            "      \n",
            "      Here is how to fix this error in the main use cases:\n",
            "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
            "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
            "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
            "      - if the 'sklearn' package is used by one of your dependencies,\n",
            "        it would be great if you take some time to track which package uses\n",
            "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
            "      - as a last resort, set the environment variable\n",
            "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
            "      \n",
            "      More information is available at\n",
            "      https://github.com/scikit-learn/sklearn-pypi-package\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy sklearn PyPDF2 nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYLPcpj8eUkl",
        "outputId": "6af79a50-f6eb-46ce-df85-afb8f1015d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by482X8peXHw",
        "outputId": "f839c45f-9023-4faa-f953-5dcdf2253f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.7.2\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "ZbIbqodLeaTW",
        "outputId": "244b27b0-65d5-4b18-d806-027e9afaae91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compétences\n",
            "Visualisation & Reporting\n",
            "Tableaux de bor d, dataviz,\n",
            "reporting\n",
            "Outils & Langages\n",
            "Python, R, Git, Jup yter, Po wer\n",
            "BI, Shiny\n",
            "Analyse de données\n",
            "Régr ession, classiﬁcation,\n",
            "analyses multivariées\n",
            "(ACP/MF A), modélisation\n",
            "prédictive pour appui\n",
            "décisionnel\n",
            "Gestion de données\n",
            "Netto yage, structur ation,\n",
            "intégr ation multi-sour ces,\n",
            "contr ôle qualité, cr éation\n",
            "d’indicateurs\n",
            "Soft Skills\n",
            "Analyse et esprit critique\n",
            "Rigueur et or ganisation\n",
            "Résolution de pr oblèmes\n",
            "Communication\n",
            "Travail en équipe\n",
            "Langues\n",
            "Français : Cour ant\n",
            "Anglais : Professionnel\n",
            "Arabe : Cour ant\n",
            "Réseaux sociauxNassima EL HILALI\n",
            "Data Analyst / Data Scientist\n",
            "Je suis Data Scientist en M2 Data Science et ingénieur e spécialisée en agr oéconomie,\n",
            "avec un pr oﬁl pluridisciplinair e orienté vers l’ analyse quantitative, la modélisation\n",
            "statistique et l’ aide à la décision. J’ ai de l’ expérience en manipulation et valorisation\n",
            "de données hétér ogènes, en modélisation pr édictive et en cr éation de tableaux de\n",
            "bord pour appuyer le pilotage d’ activité. Je suis disponible pour un stage de 6 mois à\n",
            "partir de fé vrier 2026.\n",
            "Diplômes et Formations\n",
            "Expériences professionnelles\n",
            "Projets académiquesnassima.elhilali.pr o@gmail.\n",
            "com\n",
            "Permis de conduir e B \n",
            "Disponible dès\n",
            "Février/Mars 2026\n",
            "Ile de Fr ance\n",
            "+33 6 03 54 78 77 \n",
            "@nassimaelhilali-hub\n",
            "@Nassima EL HILALIMaster M2 – Data Science pour la Biologie\n",
            "Depuis 2024 Institut Agr o Rennes-Angers  Rennes, FRANCE\n",
            " Machine Learning, Modèles pr édictifs, Statistiques avancées\n",
            "Diplôme d’Ingénieur d’État – Spécialisation Agr oéconomie\n",
            "De 2019  à 2024 École Nationale d’ Agricultur e (ENA)  Meknès, MAROC\n",
            "Data Scientist (Stage)\n",
            "De février 2024  à juillet 2024\n",
            "Conseil, Ingénierie, Dé veloppement (CID)  Rabat, MAROC\n",
            "Objectif : amélior er la performance économique et opér ationnelle\n",
            "d’exploitations agricoles.\n",
            "Développement d’ un modèle d’ optimisation économique (données IoT +\n",
            "terrain).\n",
            "Conception d’ outils d’ aide à la décision : pr ototype mobile (Figma) et chatbot\n",
            "IA.\n",
            "Analyse et visualisation des données pour appuyer l’ amélior ation de\n",
            "processus métier.\n",
            "Data Analyst (Stage)\n",
            "De mai 2023  à juillet 2023\n",
            "Conseil, Ingénierie, Dé veloppement (CID)  Rabat, MAROC\n",
            "Objectif : pr oduir e des insights pour la prise de décision str atégique.\n",
            "Collecte et consolidation de données climatiques & économiques multi-\n",
            "sour ces.\n",
            "Développement de dashboar ds automatisés et analyses de tendances.\n",
            "Traitement statistique (Stage)\n",
            "De janvier 2023  à février 2023\n",
            "Oﬃce National du Conseil Agricole (ONCA)  Région du Saiss, MAROC\n",
            "Analyses statistiques pour orienter les r ecommandations agricoles.\n",
            "Création de gr aphiques et tableaux de bor d automatisés.\n",
            "Char gée Qualité - Analyse des Données (Stage)\n",
            "D'août 2022  à septembr e 2022\n",
            "Azur a (Gr and gr oupe agr oalimentair e) Agadir, MAROC\n",
            "Analyse de données de pr oduction et suivi d’indicateurs qualité.\n",
            "Classiﬁcation d’images d’ espèces animales — CNN (2025)\n",
            "2025 Institut Agr o-Rennes  Rennes\n",
            "Modèle CNN pour classiﬁer 10 espèces animales à partir d’images.\n",
            "Pipeline complet + data augmentation pour amélior er la r obustesse.\n",
            "Analyse des performances et interpr étation des err eurs (Python, PyT orch).\n",
            "Dashboar ds décisionnels — Shiny (2025)\n",
            "2025 Institut Agr o-Rennes  Rennes\n",
            "Tableaux de bor d inter actifs pour suivr e des indicateurs.\n",
            "Structur ation des données et visualisations sous R/Shiny .\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_resume_text(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in range(len(reader.pages)):\n",
        "            text += reader.pages[page].extract_text()\n",
        "    return text\n",
        "\n",
        "# Example usage:\n",
        "resume_text = extract_resume_text('CV__Nassima_EL_HILALI.pdf')\n",
        "print(resume_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFgl4YoVfJGB",
        "outputId": "17c1e14a-4415-4050-bf03-68a0789f8faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.0.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h5M4uZyqfMeV"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H79-wM4ifO0s",
        "outputId": "7afd9a4e-1435-4303-d053-292ad0ea1ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compétences\n",
            "Visualisation & Reporting\n",
            "Tableaux de bor d, dataviz,\n",
            "reporting\n",
            "Outils & Langages\n",
            "Python, R, Git, Jup yter, Po wer\n",
            "BI, Shiny\n",
            "Analyse de données\n",
            "Régr ession, classiﬁcation,\n",
            "analyses multivariées\n",
            "(ACP/MF A), modélisation\n",
            "prédictive pour appui\n",
            "décisionnel\n",
            "Gestion de données\n",
            "Netto yage, structur ation,\n",
            "intégr ation multi-sour ces,\n",
            "contr ôle qualité, cr éation\n",
            "d’indicateurs\n",
            "Soft Skills\n",
            "Analyse et esprit critique\n",
            "Rigueur et or ganisation\n",
            "Résolution de pr oblèmes\n",
            "Communication\n",
            "Travail en équipe\n",
            "Langues\n",
            "Français : Cour ant\n",
            "Anglais : Professionnel\n",
            "Arabe : Cour ant\n",
            "Réseaux sociauxNassima EL HILALI\n",
            "Data Analyst / Data Scientist\n",
            "Je suis Data Scientist en M2 Data Science et ingénieur e spécialisée en agr oéconomie,\n",
            "avec un pr oﬁl pluridisciplinair e orienté vers l’ analyse quantitative, la modélisation\n",
            "statistique et l’ aide à la décision. J’ ai de l’ expérience en manipulation et valorisation\n",
            "de données hétér ogènes, en modélisation pr édictive et en cr éation de tableaux de\n",
            "bord pour appuyer le pilotage d’ activité. Je suis disponible pour un stage de 6 mois à\n",
            "partir de fé vrier 2026.\n",
            "Diplômes et Formations\n",
            "Expériences professionnelles\n",
            "Projets académiquesnassima.elhilali.pr o@gmail.\n",
            "com\n",
            "Permis de conduir e B \n",
            "Disponible dès\n",
            "Février/Mars 2026\n",
            "Ile de Fr ance\n",
            "+33 6 03 54 78 77 \n",
            "@nassimaelhilali-hub\n",
            "@Nassima EL HILALIMaster M2 – Data Science pour la Biologie\n",
            "Depuis 2024 Institut Agr o Rennes-Angers  Rennes, FRANCE\n",
            " Machine Learning, Modèles pr édictifs, Statistiques avancées\n",
            "Diplôme d’Ingénieur d’État – Spécialisation Agr oéconomie\n",
            "De 2019  à 2024 École Nationale d’ Agricultur e (ENA)  Meknès, MAROC\n",
            "Data Scientist (Stage)\n",
            "De février 2024  à juillet 2024\n",
            "Conseil, Ingénierie, Dé veloppement (CID)  Rabat, MAROC\n",
            "Objectif : amélior er la performance économique et opér ationnelle\n",
            "d’exploitations agricoles.\n",
            "Développement d’ un modèle d’ optimisation économique (données IoT +\n",
            "terrain).\n",
            "Conception d’ outils d’ aide à la décision : pr ototype mobile (Figma) et chatbot\n",
            "IA.\n",
            "Analyse et visualisation des données pour appuyer l’ amélior ation de\n",
            "processus métier.\n",
            "Data Analyst (Stage)\n",
            "De mai 2023  à juillet 2023\n",
            "Conseil, Ingénierie, Dé veloppement (CID)  Rabat, MAROC\n",
            "Objectif : pr oduir e des insights pour la prise de décision str atégique.\n",
            "Collecte et consolidation de données climatiques & économiques multi-\n",
            "sour ces.\n",
            "Développement de dashboar ds automatisés et analyses de tendances.\n",
            "Traitement statistique (Stage)\n",
            "De janvier 2023  à février 2023\n",
            "Oﬃce National du Conseil Agricole (ONCA)  Région du Saiss, MAROC\n",
            "Analyses statistiques pour orienter les r ecommandations agricoles.\n",
            "Création de gr aphiques et tableaux de bor d automatisés.\n",
            "Char gée Qualité - Analyse des Données (Stage)\n",
            "D'août 2022  à septembr e 2022\n",
            "Azur a (Gr and gr oupe agr oalimentair e) Agadir, MAROC\n",
            "Analyse de données de pr oduction et suivi d’indicateurs qualité.\n",
            "Classiﬁcation d’images d’ espèces animales — CNN (2025)\n",
            "2025 Institut Agr o-Rennes  Rennes\n",
            "Modèle CNN pour classiﬁer 10 espèces animales à partir d’images.\n",
            "Pipeline complet + data augmentation pour amélior er la r obustesse.\n",
            "Analyse des performances et interpr étation des err eurs (Python, PyT orch).\n",
            "Dashboar ds décisionnels — Shiny (2025)\n",
            "2025 Institut Agr o-Rennes  Rennes\n",
            "Tableaux de bor d inter actifs pour suivr e des indicateurs.\n",
            "Structur ation des données et visualisations sous R/Shiny .\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_resume_text(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in range(len(reader.pages)):\n",
        "            text += reader.pages[page].extract_text()\n",
        "    return text\n",
        "\n",
        "# Example usage:\n",
        "resume_text = extract_resume_text('CV__Nassima_EL_HILALI.pdf')\n",
        "print(resume_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdyuiluBfeW3",
        "outputId": "fe41b75f-2e68-42a5-bcbe-b43e6fcf4abe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "compétences \n",
            " visualisation reporting \n",
            " tableaux de bor dataviz \n",
            " reporting \n",
            " outils langages \n",
            " python r git jup yter po wer \n",
            " bi shiny \n",
            " analyse de données \n",
            " régr ession classiﬁcation \n",
            " analyses multivariées \n",
            " acp mf modélisation \n",
            " prédictive pour appui \n",
            " décisionnel \n",
            " gestion de données \n",
            " netto yage structur ation \n",
            " intégr ation multi sour ces \n",
            " contr ôle qualité cr éation \n",
            " d’indicateurs \n",
            " soft skills \n",
            " analyse et esprit critique \n",
            " rigueur et ganisation \n",
            " résolution de pr oblèmes \n",
            " communication \n",
            " travail en équipe \n",
            " langues \n",
            " français cour ant \n",
            " anglais professionnel \n",
            " arabe cour ant \n",
            " réseaux sociauxnassima el hilali \n",
            " data analyst data scientist \n",
            " je suis data scientist en m2 data science et ingénieur e spécialisée en agr oéconomie \n",
            " avec un pr oﬁl pluridisciplinair e orienté vers l ’ analyse quantitative la modélisation \n",
            " statistique et l ’ aide à la décision j ’ ai de l ’ expérience en manipulation et valorisation \n",
            " de données hétér ogènes en modélisation pr édictive et en cr éation de tableaux de \n",
            " bord pour appuyer le pilotage ’ activité je suis disponible pour un stage de 6 mois à \n",
            " partir de fé vrier 2026 \n",
            " diplômes et formations \n",
            " expériences professionnelles \n",
            " projets académiquesnassima.elhilali.pr o@gmail \n",
            " com \n",
            " permis de conduir e b  \n",
            " disponible dès \n",
            " février mars 2026 \n",
            " ile de fr ance \n",
            " +33 6 03 54 78 77  \n",
            " @nassimaelhilali hub \n",
            " @nassima el hilalimaster m2 – data science pour la biologie \n",
            " depuis 2024 institut agr rennes angers   rennes france \n",
            "  machine learning modèles pr édictifs statistiques avancées \n",
            " diplôme d’ingénieur d’état – spécialisation agr oéconomie \n",
            " de 2019   à 2024 école nationale ’ agricultur e ena   meknès maroc \n",
            " data scientist stage \n",
            " de février 2024   à juillet 2024 \n",
            " conseil ingénierie dé veloppement cid   rabat maroc \n",
            " objectif amélior er la performance économique et opér ationnelle \n",
            " d’exploitations agricoles \n",
            " développement ’ un modèle ’ optimisation économique données iot \n",
            " terrain \n",
            " conception ’ outils ’ aide à la décision pr ototype mobile figma et chatbot \n",
            " ia \n",
            " analyse et visualisation des données pour appuyer l ’ amélior ation de \n",
            " processus métier \n",
            " data analyst stage \n",
            " de mai 2023   à juillet 2023 \n",
            " conseil ingénierie dé veloppement cid   rabat maroc \n",
            " objectif pr oduir e des insights pour la prise de décision str atégique \n",
            " collecte et consolidation de données climatiques économiques multi- \n",
            " sour ces \n",
            " développement de dashboar ds automatisés et analyses de tendances \n",
            " traitement statistique stage \n",
            " de janvier 2023   à février 2023 \n",
            " oﬃce national du conseil agricole onca   région du saiss maroc \n",
            " analyses statistiques pour orienter les r ecommandations agricoles \n",
            " création de gr aphiques et tableaux de bor automatisés \n",
            " char gée qualité analyse des données stage \n",
            " d'août 2022   à septembr e 2022 \n",
            " azur gr gr oupe agr oalimentair e agadir maroc \n",
            " analyse de données de pr oduction et suivi d’indicateurs qualité \n",
            " classiﬁcation d’images ’ espèces animales — cnn 2025 \n",
            " 2025 institut agr rennes   rennes \n",
            " modèle cnn pour classiﬁer 10 espèces animales à partir d’images \n",
            " pipeline complet data augmentation pour amélior er la r obustesse \n",
            " analyse des performances et interpr étation des err eurs python pyt orch \n",
            " dashboar ds décisionnels — shiny 2025 \n",
            " 2025 institut agr rennes   rennes \n",
            " tableaux de bor inter actifs pour suivr e des indicateurs \n",
            " structur ation des données et visualisations sous r shiny\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenize and remove stopwords/punctuation\n",
        "    doc = nlp(text)\n",
        "    clean_tokens = [token.text for token in doc if token.text not in stop_words and token.text not in string.punctuation]\n",
        "\n",
        "    return \" \".join(clean_tokens)\n",
        "\n",
        "# Example usage\n",
        "cleaned_resume = preprocess_text(resume_text)\n",
        "print(cleaned_resume)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-zLkdu9fs3J",
        "outputId": "23650e68-fad8-46e4-e406-1292a3e4e140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "looking data scientist 3 years experience python machine learning data analysis ...\n"
          ]
        }
      ],
      "source": [
        "job_description = \"\"\"We are looking for a Data Scientist with 3+ years of experience in Python, Machine Learning, and Data Analysis...\"\"\"\n",
        "cleaned_job_description = preprocess_text(job_description)\n",
        "print(cleaned_job_description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4gVY_9rCfwrP"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def vectorize_texts(resume, job_desc):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([resume, job_desc])\n",
        "    return vectors\n",
        "\n",
        "resume_vector, job_desc_vector = vectorize_texts(cleaned_resume, cleaned_job_description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kWH3TjSgDZ3",
        "outputId": "c85fc584-1edf-471c-c96d-3ac63a6cf29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resume-Job Description Similarity Score: 0.08985341931511699\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "similarity_score = cosine_similarity(resume_vector, job_desc_vector)\n",
        "print(f\"Resume-Job Description Similarity Score: {similarity_score[0][0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp4DdSwpf1Cs",
        "outputId": "e1597dfc-a690-40aa-fd2a-ce3968babeba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.52.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (2.1.2)\n",
            "Requirement already satisfied: packaging>=20 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (2.3.3)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.33.2)\n",
            "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (22.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (2.32.5)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (6.5.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.27.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqeYn9lXgZKO",
        "outputId": "43eac245-c398-4241-b12c-57163673bc21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "2025-12-08 15:12:03.607 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.802 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run C:\\Users\\dell\\AppData\\Roaming\\Python\\Python313\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
            "2025-12-08 15:12:03.802 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.803 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.804 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.804 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.805 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.807 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.810 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.812 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.815 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.818 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.819 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.820 Session state does not function when running a script without `streamlit run`\n",
            "2025-12-08 15:12:03.822 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.824 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-08 15:12:03.827 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import PyPDF2\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract resume text from a PDF\n",
        "def extract_resume_text(file):\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in range(len(reader.pages)):\n",
        "        text += reader.pages[page].extract_text()\n",
        "    return text\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    doc = nlp(text)\n",
        "    clean_tokens = [token.text for token in doc if token.text not in stop_words and token.text not in string.punctuation]\n",
        "    return \" \".join(clean_tokens)\n",
        "\n",
        "# Vectorize text and calculate cosine similarity\n",
        "def calculate_similarity(resume, job_desc):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([resume, job_desc])\n",
        "    similarity_score = cosine_similarity(vectors)[0][1]\n",
        "    return similarity_score\n",
        "\n",
        "# Streamlit App\n",
        "st.title(\"Resume Classifier and Job Matching System\")\n",
        "\n",
        "# Upload resume\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (PDF)\", type=\"pdf\")\n",
        "\n",
        "# Job description input\n",
        "job_desc = st.text_area(\"Paste Job Description\", height=150)\n",
        "\n",
        "# If both resume and job description are provided\n",
        "if uploaded_file and job_desc:\n",
        "    resume_text = extract_resume_text(uploaded_file)\n",
        "    cleaned_resume = preprocess_text(resume_text)\n",
        "    cleaned_job_description = preprocess_text(job_desc)\n",
        "\n",
        "    similarity_score = calculate_similarity(cleaned_resume, cleaned_job_description)\n",
        "\n",
        "    # Display similarity score\n",
        "    st.write(f\"Resume-Job Description Similarity Score: {similarity_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZBrFu1SggYx",
        "outputId": "53b6f7c0-e8cc-4511-cf19-cf8b251237b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (7.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyngrok) (6.0.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igpP9NnvkXZu",
        "outputId": "34c31464-6f22-44b4-aeb0-8567b92f98c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading ngrok ...\n",
            "Downloading ngrok: 0%\n",
            "Downloading ngrok: 1%\n",
            "Downloading ngrok: 2%\n",
            "Downloading ngrok: 3%\n",
            "Downloading ngrok: 4%\n",
            "Downloading ngrok: 5%\n",
            "Downloading ngrok: 6%\n",
            "Downloading ngrok: 7%\n",
            "Downloading ngrok: 8%\n",
            "Downloading ngrok: 9%\n",
            "Downloading ngrok: 10%\n",
            "Downloading ngrok: 11%\n",
            "Downloading ngrok: 12%\n",
            "Downloading ngrok: 13%\n",
            "Downloading ngrok: 14%\n",
            "Downloading ngrok: 15%\n",
            "Downloading ngrok: 16%\n",
            "Downloading ngrok: 17%\n",
            "Downloading ngrok: 18%\n",
            "Downloading ngrok: 19%\n",
            "Downloading ngrok: 20%\n",
            "Downloading ngrok: 21%\n",
            "Downloading ngrok: 22%\n",
            "Downloading ngrok: 23%\n",
            "Downloading ngrok: 24%\n",
            "Downloading ngrok: 25%\n",
            "Downloading ngrok: 26%\n",
            "Downloading ngrok: 27%\n",
            "Downloading ngrok: 28%\n",
            "Downloading ngrok: 29%\n",
            "Downloading ngrok: 30%\n",
            "Downloading ngrok: 31%\n",
            "Downloading ngrok: 32%\n",
            "Downloading ngrok: 33%\n",
            "Downloading ngrok: 34%\n",
            "Downloading ngrok: 35%\n",
            "Downloading ngrok: 36%\n",
            "Downloading ngrok: 37%\n",
            "Downloading ngrok: 38%\n",
            "Downloading ngrok: 39%\n",
            "Downloading ngrok: 40%\n",
            "Downloading ngrok: 41%\n",
            "Downloading ngrok: 42%\n",
            "Downloading ngrok: 43%\n",
            "Downloading ngrok: 44%\n",
            "Downloading ngrok: 45%\n",
            "Downloading ngrok: 46%\n",
            "Downloading ngrok: 47%\n",
            "Downloading ngrok: 48%\n",
            "Downloading ngrok: 49%\n",
            "Downloading ngrok: 50%\n",
            "Downloading ngrok: 51%\n",
            "Downloading ngrok: 52%\n",
            "Downloading ngrok: 53%\n",
            "Downloading ngrok: 54%\n",
            "Downloading ngrok: 55%\n",
            "Downloading ngrok: 56%\n",
            "Downloading ngrok: 57%\n",
            "Downloading ngrok: 58%\n",
            "Downloading ngrok: 59%\n",
            "Downloading ngrok: 60%\n",
            "Downloading ngrok: 61%\n",
            "Downloading ngrok: 62%\n",
            "Downloading ngrok: 63%\n",
            "Downloading ngrok: 64%\n",
            "Downloading ngrok: 65%\n",
            "Downloading ngrok: 66%\n",
            "Downloading ngrok: 67%\n",
            "Downloading ngrok: 68%\n",
            "Downloading ngrok: 69%\n",
            "Downloading ngrok: 70%\n",
            "Downloading ngrok: 71%\n",
            "Downloading ngrok: 72%\n",
            "Downloading ngrok: 73%\n",
            "Downloading ngrok: 74%\n",
            "Downloading ngrok: 75%\n",
            "Downloading ngrok: 76%\n",
            "Downloading ngrok: 77%\n",
            "Downloading ngrok: 78%\n",
            "Downloading ngrok: 79%\n",
            "Downloading ngrok: 80%\n",
            "Downloading ngrok: 81%\n",
            "Downloading ngrok: 82%\n",
            "Downloading ngrok: 83%\n",
            "Downloading ngrok: 84%\n",
            "Downloading ngrok: 85%\n",
            "Downloading ngrok: 86%\n",
            "Downloading ngrok: 87%\n",
            "Downloading ngrok: 88%\n",
            "Downloading ngrok: 89%\n",
            "Downloading ngrok: 90%\n",
            "Downloading ngrok: 91%\n",
            "Downloading ngrok: 92%\n",
            "Downloading ngrok: 93%\n",
            "Downloading ngrok: 94%\n",
            "Downloading ngrok: 95%\n",
            "Downloading ngrok: 96%\n",
            "Downloading ngrok: 97%\n",
            "Downloading ngrok: 98%\n",
            "Downloading ngrok: 99%\n",
            "Downloading ngrok: 100%\n",
            "                                                                                                    \n",
            "Installing ngrok ... \n",
            "                                                                                                    \n",
            "Authtoken saved to configuration file: C:\\Users\\dell\\AppData\\Local/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken cr_2mUlcTcyRemtKUFd8XUTMFyjUHN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF9NrzIekeWC",
        "outputId": "a666e03d-7cdf-4d23-8435-630c17a5f24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: C:\\Users\\dell\\AppData\\Local/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2mUoiWYULIxq7xds0QdQl3Xd0wa_7SaaUsUxNKBchM5K2Uqwf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGK3HMPQm3VR",
        "outputId": "b8fdb69e-57e8-4c5a-b3a0-ea6d9c52ff8a"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "Background processes not supported.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyngrok\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ngrok\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Start Streamlit app\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstreamlit run app.py &>/dev/null&\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Expose the port explicitly using http\u001b[39;00m\n\u001b[32m      7\u001b[39m public_url = ngrok.connect(\u001b[32m8501\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ipykernel\\zmqshell.py:669\u001b[39m, in \u001b[36mZMQInteractiveShell.system_piped\u001b[39m\u001b[34m(self, cmd)\u001b[39m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cmd.rstrip().endswith(\u001b[33m\"\u001b[39m\u001b[33m&\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    663\u001b[39m     \u001b[38;5;66;03m# this is *far* from a rigorous test\u001b[39;00m\n\u001b[32m    664\u001b[39m     \u001b[38;5;66;03m# We do not support backgrounding processes because we either use\u001b[39;00m\n\u001b[32m    665\u001b[39m     \u001b[38;5;66;03m# pexpect or pipes to read from.  Users can always just call\u001b[39;00m\n\u001b[32m    666\u001b[39m     \u001b[38;5;66;03m# os.system() or use ip.system=ip.system_raw\u001b[39;00m\n\u001b[32m    667\u001b[39m     \u001b[38;5;66;03m# if they really want a background process.\u001b[39;00m\n\u001b[32m    668\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mBackground processes not supported.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    671\u001b[39m \u001b[38;5;66;03m# we explicitly do NOT return the subprocess status code, because\u001b[39;00m\n\u001b[32m    672\u001b[39m \u001b[38;5;66;03m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[38;5;66;03m# Instead, we store the exit_code in user_ns.\u001b[39;00m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# Also, protect system call from UNC paths on Windows here too\u001b[39;00m\n\u001b[32m    675\u001b[39m \u001b[38;5;66;03m# as is done in InteractiveShell.system_raw\u001b[39;00m\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.platform == \u001b[33m\"\u001b[39m\u001b[33mwin32\u001b[39m\u001b[33m\"\u001b[39m:\n",
            "\u001b[31mOSError\u001b[39m: Background processes not supported."
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Start Streamlit app\n",
        "!streamlit run app.py &>/dev/null&\n",
        "\n",
        "# Expose the port explicitly using http\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(f\"Streamlit app is live at: {public_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dI-HKW5oMmb",
        "outputId": "4a75c180-f73f-46fd-b7bd-040ac150e079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root       11117  0.0  0.0   6484  2308 ?        S    01:23   0:00 grep streamlit\n"
          ]
        }
      ],
      "source": [
        "!ps aux | grep streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwRvEqRUoSTC"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py --server.port 8501 &>/dev/null&\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVBE6LHbnEm0",
        "outputId": "d3b4041d-d388-4e9b-d87d-6ec8d2c78f65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root       11254  0.0  0.0   6484  2256 ?        S    01:24   0:00 grep streamlit\n"
          ]
        }
      ],
      "source": [
        "!ps aux | grep streamlit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparer plusieurs CVs a une offre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
